{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca614a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(inp,mean,var):\n",
    "    std=np.sqrt(var)\n",
    "    value=(1/(np.sqrt(2*np.pi*var)))*np.exp((-1*(mean-inp)**2)/(2*var))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd33497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def membership(inp,mean_l,mean_m,mean_h,var=0.8):#l,h are the base width of the right triangle.m is the half base width of the isoceles\n",
    "    ul,um,uh=0,0,0\n",
    "    ul=gaussian(inp,mean_l,var)\n",
    "    um=gaussian(inp,mean_m,var)\n",
    "    uh=gaussian(inp,mean_h,var)\n",
    "    ULMH=np.array([[ul,um,uh]])\n",
    "    return ULMH.reshape(1,3) # matrix of dimensions 1,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde63ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(out):\n",
    "    if out>0:\n",
    "        return out\n",
    "    else:\n",
    "        return 0.1*out # leaky relu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e68d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.LMH=np.random.uniform(0,300, (2,3))# generates 2*3 matrix of random numbers between 0 to 0.5\n",
    "        self.ab=np.random.randint(1,4,(9,2))#9*2 matrix of random numbers between 1 to 4 excludiing 4\n",
    "        self.LMH_update=np.zeros((2,3))#update gonna be used during backprop\n",
    "        self.ab_update=np.zeros((9,2))#update gonna be used during backprop\n",
    "        self.LMH[0][0]=0\n",
    "        self.LMH[0][1]=0.5\n",
    "        self.LMH[0][2]=1\n",
    "        self.LMH[1][0]=0\n",
    "        self.LMH[1][1]=0.5\n",
    "        self.LMH[1][2]=1\n",
    "    def membership_class(self,inp1,inp2):\n",
    "        self.inp1=inp1\n",
    "        self.inp2=inp2\n",
    "        self.U1=membership(self.inp1,self.LMH[0][0],self.LMH[0][1],self.LMH[0][2])# matrix of dimensions 1,3\n",
    "        self.U2=membership(self.inp2,self.LMH[1][0],self.LMH[1][1],self.LMH[1][2])# matrix of dimensions 1,3   \n",
    "        \n",
    "        \n",
    "    def membership_class_node1(self,inp1,inp2):\n",
    "        self.inp1=inp1\n",
    "        self.inp2=inp2\n",
    "        self.LMH[0][0]=20\n",
    "        self.LMH[0][1]=140\n",
    "        self.LMH[0][2]=260\n",
    "        self.LMH[1][0]=0\n",
    "        self.LMH[1][1]=0.5\n",
    "        self.LMH[1][2]=1\n",
    "        self.U1=membership(self.inp1,self.LMH[0][0],self.LMH[0][1],self.LMH[0][2],var=1000)# matrix of dimensions 1,3\n",
    "        self.U2=membership(self.inp2,self.LMH[1][0],self.LMH[1][1],self.LMH[1][2])# matrix of dimensions 1,3       \n",
    "        \n",
    "    def forward_prop(self):\n",
    "        self.inp=np.array([[self.inp1],[self.inp2]])\n",
    "        #print(self.inp)\n",
    "        self.inp=self.inp.reshape(2,1) #matrix of dimensions 2*1\n",
    "        \n",
    "        self.k=np.dot(self.U1.T,self.U2)#k is a 3*3 matrix\n",
    "        \n",
    "        self.ksum=np.sum(self.k)\n",
    "        self.ksum=float(self.ksum)\n",
    "        if self.ksum==0:\n",
    "            self.ksum=1\n",
    "            \n",
    "        self.k_norm=self.k/self.ksum #k_norm is normalised\n",
    "        \n",
    "        self.w=self.k_norm.reshape(1,9)#self is a matrix of dimensions 1*9\n",
    "        \n",
    "        self.y=np.dot(self.ab,self.inp) #y is a matrix of dimensions 9*1\n",
    "        \n",
    "        self.out_before_relu=np.dot(self.w,self.y) #out is a matrix of dimension 1*1\n",
    "        \n",
    "        self.out_before_relu=float(self.out_before_relu)# typecasts matrix of size 1*1 to float\n",
    "        \n",
    "        self.out=relu(self.out_before_relu)# relu activation function is used\n",
    "        #print('LMH',self.LMH)\n",
    "    \n",
    "    def backprop_to_prev_node (self,learning_rate,last):\n",
    "        if self.out_before_relu>0:\n",
    "            self.relu_drvt=1\n",
    "        else:\n",
    "            self.relu_drvt=0.1 # derivative of relu\n",
    "            \n",
    "        self.to_prev=learning_rate*last*self.relu_drvt*(np.sum(self.ab[:,0]*self.w.T)) \n",
    "        \n",
    "        self.to_prev=float(self.to_prev)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def backprop_ab(self,learning_rate,last):\n",
    "        self.ab_update=self.ab_update+learning_rate*last*self.relu_drvt*self.w.reshape(9,1)*self.inp.T\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def backprop_LMH(self,learning_rate,last,var=0.8): # backprop with gaussian membership function. var is variance of gaussian\n",
    "        \n",
    "        self.d=(self.ksum-self.k)/(self.ksum*self.ksum) # d is a 3*3 matrix\n",
    "        \n",
    "        self.dummy=self.y.reshape(3,3)*self.d*self.k #3*3 matrix\n",
    "        \n",
    "        self.dummy1=self.dummy.sum(axis=1)# sums along rows. 3*1 matrix\n",
    "        self.dummy2=self.dummy.sum(axis=0)# sums along columns . 1*3 matrix\n",
    "        \n",
    "        self.drvt=(self.LMH-self.inp)/(2*np.sqrt(var)) # LMH is 2*3 inp is 2*1 drvt is 2*3 matrix \n",
    "        \n",
    "        self.dummy1=self.dummy1.T*self.drvt[0,:] # dummy1.T is 1*3 drvt[0,:] is 1*3 dummy1 is 1*3 \n",
    "        self.dummy2=self.dummy2*self.drvt[1,:] # dummy2 is 1*3 drvt[1,:] is 1*3 dummy2 is 1*3 \n",
    "        \n",
    "        self.LMH_update[0,:]=self.LMH_update[0,:]+learning_rate*last*self.relu_drvt*self.dummy1 # 1*3 \n",
    "        self.LMH_update[1,:]=self.LMH_update[1,:]+learning_rate*last*self.relu_drvt*self.dummy2 # 1*3 \n",
    "        \n",
    "        \n",
    "        \n",
    "    def update(self):\n",
    "        self.ab=self.ab+self.ab_update\n",
    "        self.LMH=self.LMH+self.LMH_update\n",
    "        \n",
    "    def reset(self):\n",
    "        self.LMH_update=np.zeros((2,3))\n",
    "        self.ab_update=np.zeros((9,2))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer():\n",
    "    def __init__(self):\n",
    "        self.a=0\n",
    "            \n",
    "            \n",
    "    def initalise(self,n,n_inp): # n is the number of nodes in a layer. n_inp are the number of inputs to that node.\n",
    "        self.n=n\n",
    "        self.n_inp=n_inp\n",
    "        self.weights=np.random.uniform(-1,1, (n_inp,n))#random numbers between -1 to 1 generated, n_inp*n matrix\n",
    "        self.bias=np.random.uniform(-1,1, (1,n))# 1*n matrix\n",
    "        self.activate=np.zeros((1,n))\n",
    "        self.d_activation_relu=np.zeros((1,n))\n",
    "    \n",
    "    def forwardpass(self,inp) :\n",
    "        self.inp=inp\n",
    "        self.forward=np.dot(self.inp,self.weights)+self.bias\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            self.activate[0][i]=relu(self.forward[0][i])\n",
    "            \n",
    "    def drv_activation_relu(self):\n",
    "        for i in range(self.n):\n",
    "            if self.activate[0][i] >=0:\n",
    "                self.d_activation_relu[0][i]=1\n",
    "            else:\n",
    "                self.d_activation_relu[0][i]=-0.1\n",
    "                \n",
    "                \n",
    "    def to_prev_layer(self,from_next,d_act_pre):# from_next is output from neurons ahead to this layer (backprop)\n",
    "        self.from_next=from_next# n*1  #d_act_pre is the derivative of the activation of the previous neuron\n",
    "        self.d_act_pre=d_act_pre #1*n\n",
    "        \n",
    "        \n",
    "        self.w_pre=np.dot(self.weights,self.from_next*self.d_act_pre.reshape(self.n,1))# n_inp*1\n",
    "        self.to_pre=self.w_pre #n_inp*1\n",
    "\n",
    "\n",
    "    def to_prev_layer1(self,from_next,d_act_pre):# from_next is output from neurons ahead to this layer (backprop)\n",
    "        self.from_next=from_next# n*1  #d_act_pre is the derivative of the activation of the previous neuron\n",
    "        self.d_act_pre=d_act_pre #1*n_inp\n",
    "        self.w_pre=self.weights*self.from_next*self.d_act_pre# n_inp*1\n",
    "        self.to_pre=self.w_pre #n_inp*1     \n",
    "        \n",
    "     \n",
    "    \n",
    "    def backprop_weights(self,lr,from_next,d_act_pre): #d_act_pre is 1*n, self.inp is 1*n_inp,from_next is n*1\n",
    "        self.update_weights=np.zeros((self.n_inp,self.n)) #n_inp*n\n",
    "        self.update_bias=np.zeros((1,self.n)) # 1*n\n",
    "        self.dummy_weights=np.ones((self.n_inp,self.n)) #n_inp*n\n",
    "        self.dummy_bias=np.ones((1,self.n)) #1*n\n",
    "        \n",
    "        self.update_weights=self.update_weights+lr*(self.dummy_weights*self.inp.reshape(self.n_inp,1))*from_next.reshape(1,self.n)*d_act_pre\n",
    "        self.update_bias=self.update_bias+lr*self.dummy_bias*d_act_pre*from_next.reshape(1,self.n)\n",
    "        \n",
    "    def backprop_weights1(self,lr,from_next,d_act_pre): #d_act_pre is 1*n, self.inp is 1*n_inp,from_next is n*1\n",
    "        self.update_weights=np.zeros((self.n_inp,self.n)) #n_inp*n\n",
    "        self.update_bias=np.zeros((1,self.n)) # 1*n\n",
    "        self.dummy_weights=np.ones((self.n_inp,self.n)) #n_inp*n\n",
    "        self.dummy_bias=np.ones((1,self.n)) #1*n\n",
    "        \n",
    "        self.update_weights=self.update_weights+lr*(self.dummy_weights*self.inp.reshape(self.n_inp,1))*from_next*d_act_pre\n",
    "        self.update_bias=self.update_bias+lr*self.dummy_bias*d_act_pre*from_next\n",
    "        \n",
    "    def update(self):\n",
    "        self.weights=self.weights+self.update_weights\n",
    "        self.bias=self.bias+self.update_bias\n",
    "    \n",
    "    \n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812582c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_FD001.txt\", sep=\" \",header=None)\n",
    "train=df\n",
    "train.drop([26,27],axis=1,inplace=True) #drop columns as both of them contain NaN values\n",
    "train.drop([4,5,9,10,14,20,22,23],axis=1,inplace=True) # columns with constant values\n",
    "train.columns=['ID','Cycles','OS1','OS2','S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']\n",
    "EOL=[]\n",
    "for i in train['ID']:\n",
    "        EOL.append( ((train[train['ID'] == i][\"Cycles\"]).values)[-1])\n",
    "train[\"EOL\"]=EOL\n",
    "train[\"RULf\"] = train[\"Cycles\"].div(train[\"EOL\"])\n",
    "train=train.drop(columns=['ID','EOL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ca0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_normalised=train[['S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']]\n",
    "data_min=to_be_normalised.min()\n",
    "data_max=to_be_normalised.max()\n",
    "data_min=data_min.to_numpy()#converting pandas to numpy array of dimension 14*1\n",
    "data_max=data_max.to_numpy()\n",
    "data_min=np.reshape(data_min,(1,14))#reshaping 14*1 to 1*14\n",
    "data_max=np.reshape(data_max,(1,14))\n",
    "normalised=(to_be_normalised-to_be_normalised.min())/(to_be_normalised.max()-to_be_normalised.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a510751",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']]=normalised[['S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']]\n",
    "train[\"Cycles\"]=train[\"Cycles\"]/500\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "target = train.pop('RULf')\n",
    "train_matrix=train.to_numpy()\n",
    "tar=target.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0260ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "node1=node()\n",
    "node2=node()\n",
    "node3=node()\n",
    "node4=node()\n",
    "node5=node()\n",
    "node6=node()\n",
    "node7=node()\n",
    "layer1=layer()\n",
    "layer2=layer()\n",
    "layer3=layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220299c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_matrix)\n",
    "train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a020b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.initalise(8,10) #O/P,I/P\n",
    "layer2.initalise(6,8)\n",
    "layer3.initalise(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3474ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.zeros((1,10))\n",
    "mse=0\n",
    "cycle=np.zeros((20631,1))\n",
    "Yout=np.zeros((20631,1))\n",
    "Yerr=np.zeros((20631,1))\n",
    "lr=0.01\n",
    "for i in range(0,2063):\n",
    "    for j in range(0,10):\n",
    "        inp=train_matrix[i*10+j]\n",
    "        cycle[i*10+j]=i*10+j\n",
    "    \n",
    "        print(i*10+j)\n",
    "        node1.membership_class(inp[3],inp[4])\n",
    "        node1.forward_prop()\n",
    "        node2.membership_class(inp[5],inp[6])\n",
    "        node2.forward_prop()\n",
    "        node3.membership_class(inp[7],inp[8])\n",
    "        node3.forward_prop()\n",
    "        node4.membership_class(inp[9],inp[10])\n",
    "        node4.forward_prop()\n",
    "        node5.membership_class(inp[11],inp[12])\n",
    "        node5.forward_prop()\n",
    "        node6.membership_class(inp[13],inp[14])\n",
    "        node6.forward_prop()\n",
    "        node7.membership_class(inp[15],inp[16])\n",
    "        node7.forward_prop()\n",
    "        \n",
    "        b=np.array([[inp[0],inp[1],inp[2],node1.out,node2.out,node3.out,node4.out,node5.out,node6.out,node7.out]])\n",
    "        \n",
    "        \n",
    "      \n",
    "        layer1.forwardpass(b)\n",
    "        layer2.forwardpass(layer1.activate)\n",
    "        layer3.forwardpass(layer2.activate)\n",
    "        #print(layer1.activate)\n",
    "        \n",
    "        Yout[i*10+j]=float(layer3.forward)\n",
    "        Yerr[i*10+j]=(float(layer3.forward)-tar[i*10+j])**2\n",
    "        \n",
    "        layer1.drv_activation_relu()\n",
    "        layer2.drv_activation_relu()\n",
    "        layer3.drv_activation_relu\n",
    "        \n",
    "        \n",
    "        err=2*(tar[i*10+j]-float(layer3.forward))\n",
    "        \n",
    "        z=np.array([[1]])\n",
    "   \n",
    "        layer3.to_prev_layer1(err,1)\n",
    "        layer3.backprop_weights1(lr,err,1)\n",
    "        \n",
    "        layer2.to_prev_layer(layer3.to_pre,layer2.d_activation_relu)\n",
    "        layer2.backprop_weights(lr,layer3.to_pre,layer2.d_activation_relu)\n",
    "        \n",
    "        \n",
    "        layer1.to_prev_layer(layer2.to_pre,layer1.d_activation_relu)\n",
    "        layer1.backprop_weights(lr,layer2.to_pre,layer1.d_activation_relu)\n",
    "        \n",
    "        \n",
    "        #print(layer1.to_pre)\n",
    "        node1.backprop_to_prev_node(lr,layer1.to_pre[3][0])\n",
    "        node1.backprop_ab(lr,layer1.to_pre[3][0])\n",
    "        node1.backprop_LMH(lr,layer1.to_pre[3][0])\n",
    "        \n",
    "        \n",
    "        node2.backprop_to_prev_node(lr,layer1.to_pre[4][0])\n",
    "        node2.backprop_ab(lr,layer1.to_pre[4][0])\n",
    "        node2.backprop_LMH(lr,layer1.to_pre[4][0])\n",
    "        \n",
    "        \n",
    "        node3.backprop_to_prev_node(lr,layer1.to_pre[5][0])\n",
    "        node3.backprop_ab(lr,layer1.to_pre[5][0])\n",
    "        node3.backprop_LMH(lr,layer1.to_pre[5][0])\n",
    "        \n",
    "        node4.backprop_to_prev_node(lr,layer1.to_pre[6][0])\n",
    "        node4.backprop_ab(lr,layer1.to_pre[6][0])\n",
    "        node4.backprop_LMH(lr,layer1.to_pre[6][0])\n",
    "        \n",
    "        node5.backprop_to_prev_node(lr,layer1.to_pre[7][0])\n",
    "        node5.backprop_ab(lr,layer1.to_pre[7][0])\n",
    "        node5.backprop_LMH(lr,layer1.to_pre[7][0])\n",
    "        \n",
    "        node6.backprop_to_prev_node(lr,layer1.to_pre[8][0])\n",
    "        node6.backprop_ab(lr,layer1.to_pre[8][0])\n",
    "        node6.backprop_LMH(lr,layer1.to_pre[8][0])\n",
    "        \n",
    "        node7.backprop_to_prev_node(lr,layer1.to_pre[9][0])\n",
    "        node7.backprop_ab(lr,layer1.to_pre[9][0])\n",
    "        node7.backprop_LMH(lr,layer1.to_pre[9][0])\n",
    "        \n",
    "        print(\"out\", layer3.forward,\"tar\",tar[i*10+j],\"error\",tar[i*10+j]-layer3.forward)\n",
    "       # print(layer1.to_pre.shape)\n",
    "        #print(layer2.to_pre.shape)\n",
    "        \n",
    "        mse=mse+(tar[i*10+j]-layer3.forward)**2\n",
    "        layer3.update()\n",
    "        layer2.update()\n",
    "        layer1.update()\n",
    "        node1.update()\n",
    "        node1.reset()\n",
    "        node2.update()\n",
    "        node2.reset()\n",
    "        node3.update()\n",
    "        node3.reset()\n",
    "        node4.update()\n",
    "        node4.reset()\n",
    "        node5.update()\n",
    "        node5.reset()\n",
    "        node6.update()\n",
    "        node6.reset()\n",
    "        node7.update()\n",
    "        node7.reset()\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse)\n",
    "print(mse/20630) #all input variables present+ 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis([0,20630 , 0, 1])\n",
    "plt.scatter(cycle,Yerr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lmh1\",node1.LMH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33544954",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tar[20000:],Yout[20000:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783643f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tar[20000:],Yerr[20000:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"test_FD001.txt\", sep=\" \",header=None)\n",
    "test=df1\n",
    "test.drop([26,27],axis=1,inplace=True) #drop columns as both of them contain NaN values\n",
    "test.drop([4,5,9,10,14,20,22,23],axis=1,inplace=True) # columns with constant values\n",
    "test.columns=['ID','Cycles','OS1','OS2','S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373be9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_normalised1=test[['S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']]\n",
    "\n",
    "#min max normalisation\n",
    "normalised1=(to_be_normalised1-data_min)/(data_max-data_min)\n",
    "test[['S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']]=normalised1[['S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']]\n",
    "test[\"Cycles\"]=test[\"Cycles\"]/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf75aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_test(a):\n",
    "    b=np.zeros((1,10))\n",
    "    test_pred=test.loc[test['ID'] == a]\n",
    "    inp_test_pred=test_pred[['Cycles','OS1','OS2','S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']]\n",
    "    test_matrix=inp_test_pred.to_numpy()\n",
    "    Y_pred=[0]*len(test_matrix)\n",
    "    for j in range(0,len(test_matrix)):\n",
    "        inp=test_matrix[j]\n",
    "        #print(test_matrix[j])\n",
    "        #print(j)\n",
    "        node1.membership_class(inp[3],inp[4])\n",
    "        node1.forward_prop()\n",
    "        node2.membership_class(inp[5],inp[6])\n",
    "        node2.forward_prop()\n",
    "        node3.membership_class(inp[7],inp[8])\n",
    "        node3.forward_prop()\n",
    "        node4.membership_class(inp[9],inp[10])\n",
    "        node4.forward_prop()\n",
    "        node5.membership_class(inp[11],inp[12])\n",
    "        node5.forward_prop()\n",
    "        node6.membership_class(inp[13],inp[14])\n",
    "        node6.forward_prop()\n",
    "        node7.membership_class(inp[15],inp[16])\n",
    "        node7.forward_prop()\n",
    "        \n",
    "        b=np.array([[inp[0],inp[1],inp[2],node1.out,node2.out,node3.out,node4.out,node5.out,node6.out,node7.out]])\n",
    "        \n",
    "        \n",
    "      \n",
    "        layer1.forwardpass(b)\n",
    "        layer2.forwardpass(layer1.activate)\n",
    "        layer3.forwardpass(layer2.activate)\n",
    "        #Y_pred[j]=float(1-layer3.forward)\n",
    "        Y_pred[j]=float(layer3.forward)\n",
    "        #Y_pred=1-np.array(Y_pred)\n",
    "        #Y_pred=np.array(Y_pred)\n",
    "        #print(Y_pred.shape)\n",
    "        #print(Y_pred)\n",
    "    \n",
    "    \n",
    "    #plt.plot(test_pred['Cycles']*500,Y_pred,c='red')\n",
    "    #plt.show()\n",
    "    Y_pred=np.array(Y_pred)\n",
    "    #print(Y_pred)\n",
    "    \n",
    "\n",
    "    return Y_pred ,test_pred['Cycles'].to_numpy().reshape(-1,1)*500,test_pred['Cycles'].max()*500\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"test_FD001.txt\", sep=\" \",header=None)\n",
    "test2=df2\n",
    "test2.drop([26,27],axis=1,inplace=True) #drop columns as both of them contain NaN values\n",
    "test2.drop([4,5,9,10,14,20,22,23],axis=1,inplace=True) # columns with constant values\n",
    "test2.columns=['ID','Cycles','OS1','OS2','S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12','S13','S14']\n",
    "Truncate=[]\n",
    "for i in test2['ID']:\n",
    "        \n",
    "        Truncate.append( ((test2[test2['ID'] == i][\"Cycles\"]).values)[-1])\n",
    "new_arr = []\n",
    "for i in range(len(Truncate)):\n",
    "    if i == 0 or Truncate[i] != Truncate[i-1]:\n",
    "        new_arr.append(Truncate[i])\n",
    "        \n",
    "print(Truncate)\n",
    "print(new_arr)\n",
    "np.shape(new_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246dc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rul = pd.read_csv(\"RUL_FD001.txt\", sep=\" \",header=None)\n",
    "rul[1]=new_arr\n",
    "rul[2]=rul[0]+rul[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.linspace(1, 350, 350).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a08a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "rbf = RBF(length_scale=2.7) #long_term_trend_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "\n",
    "# Set the hyperparameters\n",
    "sigma_0 = 1\n",
    "c = 1.0#x.y+c\n",
    "p = 1#(x.y+c)^p\n",
    "\n",
    "# Create the kernel\n",
    "lin =  DotProduct(sigma_0=sigma_0, sigma_0_bounds=(1e-5, np.inf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed374e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "\n",
    "rq =  RationalQuadratic(length_scale=1, alpha=1) #irregularities_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import WhiteKernel\n",
    "\n",
    "nk = 0.2**2 * RBF(length_scale=0.1) + WhiteKernel(\n",
    "    noise_level=0.05**2, noise_level_bounds=(1e-5, 1e5)\n",
    ")#noise kernel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7885b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RUL(z):\n",
    "    results=np.zeros((100,1))\n",
    "    truncate=np.zeros((100,1))\n",
    "\n",
    "    Y_train,X_train,dummy=pred_test(z)\n",
    "\n",
    "    Y_train=1-Y_train\n",
    "#Y_train=Y_train*100\n",
    "    gaussian_process = GaussianProcessRegressor(kernel, normalize_y=False)\n",
    "    Y_mean=Y_train.mean()\n",
    "\n",
    "    X_train=X_train.reshape(-1,1)\n",
    "    gaussian_process.fit(X_train,Y_train)\n",
    "    \n",
    "    mean_y_pred, std_y_pred = gaussian_process.predict(X_test, return_std=True)\n",
    "    #mean_y_pred += Y_mean\n",
    "    plt.plot(X_train, Y_train, color=\"black\", linestyle=\"dashed\", label=\"Measurements\")\n",
    "    plt.plot(X_test, mean_y_pred, color=\"tab:blue\", alpha=0.4, label=\"Gaussian process\")\n",
    "    plt.fill_between(\n",
    "        X_test.ravel(),\n",
    "        mean_y_pred - std_y_pred,\n",
    "        mean_y_pred + std_y_pred,\n",
    "        color=\"tab:blue\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    for i in range(349):\n",
    "        if (mean_y_pred[i]*mean_y_pred[i+1]<0):\n",
    "            print(X_test[i])\n",
    "            results[j-1]=X_test[i]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a84254",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=rbf+nk+lin+rq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=np.zeros((100,1))\n",
    "truncate=np.zeros((100,1))\n",
    "for j in range(1,101):\n",
    "    print(j)\n",
    "    X_test = np.linspace(1, 400, 400).reshape(-1,1)\n",
    "    Y_train,X_train,truncate[j-1]=pred_test(j)\n",
    "\n",
    "    Y_train=1-Y_train\n",
    "    #Y_train=Y_train*100\n",
    "    gaussian_process = GaussianProcessRegressor(kernel, normalize_y=False)\n",
    "    Y_mean=Y_train.mean()\n",
    "    X_train=X_train.reshape(-1,1)\n",
    "    gaussian_process.fit(X_train,Y_train)\n",
    "    mean_y_pred, std_y_pred = gaussian_process.predict(X_test, return_std=True)\n",
    "    plt.plot(X_train, Y_train, color=\"black\", linestyle=\"dashed\", label=\"Measurements\")\n",
    "    plt.plot(X_test, mean_y_pred, color=\"tab:blue\", alpha=0.4, label=\"Gaussian process\")\n",
    "    plt.fill_between(\n",
    "    X_test.ravel(),\n",
    "    mean_y_pred - std_y_pred,\n",
    "    mean_y_pred + std_y_pred,\n",
    "    color=\"tab:blue\",\n",
    "    alpha=0.2,\n",
    "    )\n",
    "    plt.xlabel(\"Cycles\")\n",
    "    plt.ylabel(\"Engine Health\")\n",
    "\n",
    "    plt.show()\n",
    "    for i in range(349):\n",
    "        if (mean_y_pred[i]*mean_y_pred[i+1]<0):\n",
    "            print(\"result\",X_test[i])\n",
    "            print(\"actual\",rul[2][j-1])\n",
    "            \n",
    "            results[j-1]=X_test[i]\n",
    "            break\n",
    "    for i in range(349):\n",
    "        if (mean_y_pred[i]- std_y_pred[i]*mean_y_pred[i+1]- std_y_pred[i+1]<0):\n",
    "            print(\"lower band\",X_test[i])\n",
    "            results[j-1]=X_test[i]\n",
    "            break\n",
    "            \n",
    "    for i in range(349):\n",
    "        if (mean_y_pred[i]+ std_y_pred[i]*mean_y_pred[i+1]+ std_y_pred[i+1]<0):\n",
    "            print(\"upper band\",X_test[i])\n",
    "            results[j-1]=X_test[i]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b90dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rul1 = pd.read_csv(\"RUL_FD001.txt\", sep=\" \",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2726d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in results:\n",
    "    #print(i)\n",
    "    if i==0:\n",
    "        count=count+1\n",
    "print(count)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rul1[1]=results\n",
    "rul1[2]=truncate\n",
    "rul1[3]=rul1[0]+rul1[2]#final RUL\n",
    "rul1[4]=rul1[3]-rul1[1]#error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rul1 = rul1[(rul1[[1]] != 0).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rul1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d037bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "error=rul1.pop(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "er=error.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ersq=0\n",
    "for i in range(100):\n",
    "    print(i+1,er[i])\n",
    "    ersq=ersq+(er[i])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68781861",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=(ersq/i)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
